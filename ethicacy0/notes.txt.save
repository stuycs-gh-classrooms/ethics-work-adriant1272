Topic: Ludicium Ex Machinae

Thing 1:
PRIVATIZING SENTENCING: A DELEGATION FRAMEWORK FOR RECIDIVISM RISK ASSESSMENT
Andrea Nishi
Columbia Law Review, Vol. 119, No. 6 (OCTOBER 2019), pp. 1671-1710 (40 pages)
https://www.jstor.org/stable/26794353

- contract with private companies to develop this; hard for govt to see inside da machine
	- judges and defendants cannot access this info
	- "in a 2016 case from Wisconsin, a private developer denied an offenderâ€™s request for information about the algorithm that was used to determine his sentence on the ground that it was a trade secret"
	- More generic black box problem; how exactly to define (e.g., is recidivism second arrest in next 5 or 10 years?)
- main use of AI in court system in squo is recidivism risk assessment 
- Generic args for risk assessment tools:
	- Reduce prison population; save money
	- Free of individual bias
	- Reduce recidivism --> judge better understands defendent's rehab needs
- May have chance to review what is fed into AI, but not what it spits out. 
	- Equal protection challenge --> may consider protected characteristics 
- Algorithms have an air of legitimacy and science 
	- companies have competative incentive to maintain this
	- in Zilly v. State of Wisconsin, judge doubled sentence on basis of risk assesment 
- Opacity problems:
	1. Legal: algorithm protected by trade secrets
	2. Tech: judges and defendants often do not have relevant technical experitise to understand --> really hard to solve; compounds as tech develops
	- e.g., State of Wisconsion v. Loomis --> Eric Loomis sentenced to 6 years by algo 
		- Trade secrets invoked to prevent review of algo, algo had same info that defendant had access too 
	- Developers themselves cannot fully understand ML model
- private developers make choices about what data to use and how to use it --> undue influence in process
	- developers can make choices on what to include without consulting state sentencing laws


Competing Algorithms for Law: Sentencing, Admissions, and Employment
Saul Levmore, Frank Fagan
The University of Chicago Law Review, Vol. 88, No. 2 (March 2021), pp. 367-412 (46 pages)
https://www.jstor.org/stable/26986410

- Proposal: have companies compete to perform well with lockbox data
- government cannot just shop around for an algo to use --> prosecutors have skwewed incentives


Ai Enforcement: Examining the Impact of Ai on Judicial Fairness and Public Safety
19 Pages
Posted: 9 Aug 2023
Yi-Jen (Ian) Ho
Tulane University - A.B. Freeman School of Business
https://dx.doi.org/10.2139/ssrn.4533047

- homogonize judge's decisions --> independent judging is important for judicial impartiality 
- Black defendents get worse punishment from Ai than white defendants by 5.6% (change of alternative punishment), 4.3%(higher chance of incarceration), and 30.7% (lower chance of higher imprisonment)
